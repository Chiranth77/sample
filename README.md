| *TITLE* | *METHODOLOGY* | *STRENGTHS* | *LIMITATIONS* |
|----------|-----------------|---------------|-----------------|
| *Communication-Efficient Personalized Federated Meta-Learning in Edge Networks* | Introduces a communication-efficient approach to federated meta-learning that integrates personalized parameters for better model adaptation while reducing network communication overhead. | Minimizes communication costs and supports devices with limited resources, achieving a balance between global and local model performance. | Implementation can be complex; requires extensive tuning for diverse settings; personalization could lead to challenges in model convergence. |
| *A Differentially Private Federated Learning Model Against Poisoning Attacks in Edge Computing* | Proposes a weight-based anomaly detection system to identify and block malicious parameter updates from devices, coupled with differential privacy to maintain data confidentiality. | Strong privacy protection, efficient communication, and effective mitigation of poisoning attacks. | Assumes all clients are benign, which may not hold true; adding noise could affect accuracy, depending on the effectiveness of anomaly detection. |
| *FEDSECURITY: A Benchmark for Attacks and Defenses in Federated Learning and Federated LLMs* | Combines FedAttacker and FedDefender to simulate various adversarial attacks and implement defensive mechanisms like norm clipping and Krum. The flexible design allows users to customize and test different security strategies in federated training environments. | Robust and comprehensive tool for evaluating security, with easy customization for different scenarios. Tested in real-world applications including federated training of LLMs. | Security measures might impact overall model performance, and the effectiveness of the framework heavily relies on user expertise in configuring attack and defense strategies. |
| *Federated Learning for Internet of Things: A Comprehensive Survey* | Presents a federated transfer learning (FTL) framework integrating differential privacy to support learning across heterogeneous data sources while safeguarding privacy. | Combines federated learning and transfer learning, offering robust privacy protection without needing a trusted server; highlights the benefits of cross-data knowledge sharing. | Potentially less effective if source datasets are very different from the target, risking negative transfer effects; specific conditions must be met for optimal results. |
| *Privacy-Preservation Techniques in Federated Learning: An Insightful Survey from a GDPR Perspective* | Reviews a range of privacy-preserving methods in federated learning, with a focus on compliance with GDPR. Discusses techniques like secure aggregation, differential privacy, homomorphic encryption, and more. | Addresses key legal and ethical data privacy concerns, providing a thorough overview of existing privacy methods and future research directions. | Complexity in practical implementation; may not fully explore privacy-performance trade-offs; GDPR compliance can be challenging to enforce in diverse environments. |
| *Differentially Private Federated Learning: A Systematic Review* | Systematically reviews over 70 studies on differentially private federated learning, offering a new taxonomy based on privacy definitions across different scenarios (horizontal, vertical, transfer). | Comprehensive and structured analysis; proposes a new classification that improves clarity in privacy discussions. | No empirical validation; limited focus on real-world applications and a lack of quantitative comparison of privacy-performance trade-offs. |
| *IMPROVING FEDERATED LEARNING PERSONALIZATION VIA MODEL AGNOSTIC META LEARNING* | Connects federated learning with model-agnostic meta-learning (MAML), presenting a modified Federated Averaging (FedAvg) with a two-stage training and fine-tuning process for personalized performance. | Demonstrates improved personalized accuracy; effectively combines meta-learning with federated learning. | Complex implementation; results are validated mainly on specific datasets, limiting generalizability. Assumes sufficient computational resources for fine-tuning. |
| *Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks* | Introduces the MAML algorithm, which trains models to quickly adapt to new tasks using minimal data. Works by optimizing parameters to require fewer updates for new tasks. | General and flexible, compatible with various tasks like classification, regression, and reinforcement learning; state-of-the-art in few-shot learning. | High computational complexity due to second-order derivatives; may struggle with highly diverse or unrelated tasks. |
| *Communication-Efficient Learning of Deep Networks from Decentralized Data* | Implements federated learning to train models across decentralized devices, reducing communication by using the Federated Averaging (FedAvg) algorithm. Ensures privacy by avoiding raw data transfers. | Privacy-preserving and efficient, with significant reductions in communication compared to traditional methods; robust against real-world data variations. | Complex to manage non-IID data at scale, requiring reliable communication infrastructure. |
| *Federated Learning of a Mixture of Global and Local Models* | Proposes a new optimization method balancing global and local models using a penalty parameter to control trade-offs, with a novel algorithm (L2GD) for reducing communication. | Efficiently handles heterogeneous data and reduces communication rounds; generalizable for other personalized FL settings. | Sensitive to the choice of penalty parameter; variability in local steps may affect convergence. |
| *Differentially Private Federated Learning on Heterogeneous Data* | Introduces DP-SCAFFOLD, combining differential privacy with control variates to address data heterogeneity and privacy in federated learning. | Strong balance between privacy and utility; fewer communication rounds needed, enhancing efficiency. | Performance sensitive to noise addition and local update count; complex to implement and fine-tune. |
| *Federated Learning with CNNs for Medical Image Segmentation (2022)* | Developed a federated learning system utilizing CNNs for segmenting medical images, with an emphasis on patient data privacy through the use of secure aggregation and encryption. Enables collaborative model training across hospitals without direct data sharing. | Achieves strong segmentation performance while maintaining privacy; uses encryption to safeguard model updates and prevent data breaches. | Primarily designed for the medical domain, which may limit applicability to other areas; lacks comprehensive testing for robustness against adversarial threats. |
| *Securing CNN Models in Federated Learning Through Homomorphic Encryption (2020)* | Implements homomorphic encryption in federated learning with CNNs, enabling model training without revealing raw data by performing encrypted computation. | Strong privacy preservation suitable for sensitive data like healthcare and finance; maintains model integrity. | High computational costs, which may hinder scalability for larger datasets or complex models. |
| *A Blockchain-Based Framework for Federated Learning with CNNs (2022)* | Integrates blockchain technology with federated learning to track model updates on an immutable ledger, ensuring authenticity and security. | Combines security and transparency, enhancing trust in multi-party environments. | High computational and communication costs, limiting scalability for resource-constrained applications. |
| *Lightweight Federated Learning with CNNs for IoT Devices (2021)* | Proposes a lightweight framework tailored for IoT, focusing on reducing communication and computational demands while maintaining security through encryption. | Suitable for resource-limited settings, efficient communication, and quick model updates. | May struggle with large datasets or deep CNN architectures; performance may degrade with complexity. |
| *Federated Adversarial Learning with CNNs for Secure Model Training (2021)* | Combines adversarial learning techniques with CNNs in federated learning to enhance model robustness against adversarial attacks. Involves generating adversarial examples at client-side and refining the global model. | Enhances security by improving model resistance to adversarial attacks; ensures better generalization across diverse clients. | Requires extensive tuning of hyperparameters; additional computational costs may impact scalability. |
| *Federated Model Distillation with Noise-Free Differential Privacy* | Proposes a federated model distillation framework using noise-free differential privacy, allowing knowledge sharing without the performance loss from typical noise addition. | Achieves strong privacy guarantees without sacrificing model performance; suitable for collaborative scenarios with limited private data. | Potential biases from public datasets used in distillation; performance could be sensitive to dataset variations. |
| *Federated Learning of Gboard Language Models with Differential Privacy* | Utilizes Federated Learning with Differential Privacy (DP) to train Gboard models while preserving user privacy. Implements DP-FTRL with adaptive clipping to manage user contributions. | Strong privacy protection, minimal accuracy loss, and successful real-world deployment. | Increased computational complexity and challenging trade-offs between privacy and utility. |
| *Federated Visual Classification with Real-World Data Distribution* | Introduces a framework that employs federated learning for visual classification across diverse, real-world data distributions. | Generalizes well to non-IID data distributions; maintains robust performance. | Complexity in handling varying data distributions; computational demands. |
| *Projected Federated Averaging with Heterogeneous Differential Privacy* | Proposes a Projected Federated Averaging approach that leverages differential privacy, balancing utility and privacy for heterogeneous data. | Improved model utility and strong privacy preservation. | May be susceptible to biases; dependent on privacy budget distribution. |
| *Dynamic Backdoor Attacks Against Federated Learning* | Examines backdoor attacks, introducing a symbiotic network to enhance robustness. | Effective in increasing robustness against dynamic backdoor attacks. | Implementation complexity; may not generalize across all federated environments. |
| *Federated Transfer Learning with Differential Privacy* | Combines federated learning and transfer learning with differential privacy to enhance learning from multiple sources. | Strong privacy guarantees without needing a central server; improved learning through knowledge transfer. | Performance may degrade with dissimilar data sources; optimality depends on specific conditions. |
| *Improving Federated Learning Personalization via Model Agnostic Meta Learning* | Connects federated learning with model-agnostic meta-learning (MAML) for better personalization, presenting a modified Federated Averaging with two-stage training. | Enhanced personalized accuracy; effectively bridges federated learning and meta-learning. | Implementation is complex; assumptions on computational resources limit real-world applicability. |
| *Issues in Federated Learning* | Analyzes privacy leakage risks, proposing a personalized adaptive differentially private method to enhance security. | Addresses significant privacy concerns with improved convergence. | Resource-intensive implementation; dependent on client data diversity. |
| *Dynamic Backdoor Attacks Against Federated Learning* | Discusses the challenges of dynamic backdoor attacks and suggests a novel approach to mitigate such threats during federated learning. | Effective in improving model robustness against various forms of dynamic attacks. | High complexity in implementation; requires extensive testing for diverse attack scenarios. |
| *A Perspective on Decentralizing AI* | Advocates for a shift towards decentralized AI models, outlining key technologies and methods. | Enhances privacy, collaboration, and resilience against data breaches. | Challenges in implementation; potential regulatory and infrastructure barriers. |
| *Unlocking High-Accuracy Differentially Private Image Classification through Scale* | Proposes scaling techniques for differentially private image classification to achieve high accuracy. | State-of-the-art performance under privacy constraints; easy integration into existing pipelines. | High computational costs; privacy budget management is complex. |
| *Federated Learning with CNNs: A Systematic Review (2023)* | Reviews various CNN architectures and their applications in federated learning, highlighting key security vulnerabilities. | Comprehensive overview of existing work, especially around privacy and model security. | Lack of new algorithms; focuses mainly on existing methodologies without experimental validation. |
| *Dynamic Backdoor Attacks Against Federated Learning* | Discusses backdoor attacks in federated learning, introducing countermeasures. | Robust against certain attack patterns; practical in high-stakes federated applications. | May require specific configurations; could struggle in highly diverse client environments. |
| *FedCC: Robust Federated Learning with CNNs Against Poisoning Attacks (2021)* | Proposes a federated learning framework that detects and mitigates poisoning attacks using anomaly detection. | High robustness against data and model poisoning; improves security. | Training overhead; limited evaluation against sophisticated attacks. |
